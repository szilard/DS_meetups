Recent Developments in LightGBM

by James Lamb

In this talk, attendees will learn about recent developments in LightGBM, a popular open source gradient boosting library. The talk's primary goal is to educate attendees about recent work that has been done to make LightGBM easier to install and use effectively.

The talk will describe in detail a few recent additions to the library, including:
* CUDA-based GPU acceleration
* new options to make installation of a GPU-enabled Python package easier
* availability of the R package on CRAN
* new detailed documentation on hyperparameter tuning
* Dask integration for distributed training on large datasets

Demos of the new (experimental) Dask integration will be shown. The talk will conclude with a summary of new features that are coming in the future, and a call for attendees who are interested to contribute their ideas, documentation, and code to LightGBM.

Speaker Bio:

James Lamb is a software engineer at Saturn Cloud, where he works on a managed data science platform built on Dask. Before Saturn Cloud, James worked on industrial internet of things (IIoT) problems as a data scientist at AWS and Chicago-based Uptake. He is a core maintainer on LightGBM, and has contributed on other open source data science and data engineering projects such as XGBoost and prefect. James holds Masters degrees in Applied Economics (Marquette University) and Data Science (University of California, Berkeley).

Twitter: https://twitter.com/_jameslamb
GitHub: https://github.com/jameslamb
LinkedIn: https://linkedin.com/in/jameslamb1/
